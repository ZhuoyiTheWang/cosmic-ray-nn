Model 1: test_loss: 0.15584532916545868, Hyperparameters: {'ff_dim': 16, 'dropout': 0.1, 'learning_rate': 0.001, 'num_heads': 8, 'head_size': 64, 'num_encoder_layers': 16, 'num_decoder_layers': 0, 'batch_size': 32}
Model 2: test_loss: 0.9844914674758911, Hyperparameters: {'ff_dim': 48, 'dropout': 0.28570714885887566, 'learning_rate': 0.0016445845403801217, 'num_heads': 14, 'head_size': 89, 'num_encoder_layers': 9, 'num_decoder_layers': 0, 'batch_size': 33}
Model 3: test_loss: 1.4827719926834106, Hyperparameters: {'ff_dim': 9, 'dropout': 0.21534104756085318, 'learning_rate': 0.008341182143924175, 'num_heads': 6, 'head_size': 125, 'num_encoder_layers': 12, 'num_decoder_layers': 0, 'batch_size': 44}
Model 4: test_loss: 1.4826111793518066, Hyperparameters: {'ff_dim': 32, 'dropout': 0.16217936517334897, 'learning_rate': 0.006157343657751557, 'num_heads': 8, 'head_size': 59, 'num_encoder_layers': 15, 'num_decoder_layers': 0, 'batch_size': 30}
Model 5: test_loss: 0.9774826765060425, Hyperparameters: {'ff_dim': 50, 'dropout': 0.2589476095135942, 'learning_rate': 0.001748330827456348, 'num_heads': 12, 'head_size': 33, 'num_encoder_layers': 23, 'num_decoder_layers': 0, 'batch_size': 34}
Model 6: test_loss: 1.4853636026382446, Hyperparameters: {'ff_dim': 58, 'dropout': 0.26316226255364905, 'learning_rate': 0.008345380634544486, 'num_heads': 5, 'head_size': 39, 'num_encoder_layers': 23, 'num_decoder_layers': 0, 'batch_size': 40}
